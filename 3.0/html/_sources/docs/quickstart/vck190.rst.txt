#############################
Quick Start Guide for VCK190
#############################

The AMD  **DPUCVDX8G** for Versal |trade| VCK190 is a configurable computation engine dedicated to convolutional neural networks. It supports a highly optimized instruction set, enabling the deployment of most convolutional neural networks. The following instructions will help you to install the software and packages required to support the VCK190.


*************
Prerequisites
*************

System Requirements
===================

-  Confirm that your development machine meets the minimum :doc:`Host System Requirements <../reference/system_requirements>`.
-  Confirm that you have at least **100GB** of free space in the target partition.


Docker Installation
===================

Make sure that the Docker engine is installed according to the official Docker `documentation <https://docs.docker.com/engine/install/>`__ to install the Docker engine.

The Docker daemon always runs as the root user. Non-root users must be `added <https://docs.docker.com/engine/install/linux-postinstall/>`__ to the docker group. Do this now.

Perform a quick and simple test of your Docker installation by executing the following command.  This command will download a test image from Docker Hub and run it in a container. When the container runs successfully, it prints a "Hello World" message and exits. ::

	docker run hello-world

Finally, verify that the version of Docker that you have installed meets the minimum :doc:`Host System Requirements <../reference/system_requirements>` by running the following command::

	docker --version


Setup for ROCm and GPU Acceleration
===================================

For servers with ROCm and GPU-based acceleration, developers should prepare their host according to the `ROCm Docker installation documentation <https://github.com/RadeonOpenCompute/ROCm-docker/blob/master/quick-start.md>`__.

|

**********************
Installation Procedure
**********************

#. Pull an up-to-date version of one of the pre-built Vitis AI docker containers::

    docker pull xilinx/<Docker Name>:latest

   Where ``<Docker Name>`` is selected from the table below based on the desired configuration:

	.. list-table:: Vitis AI Pre-built Container Options
	   :widths: 60 40
	   :header-rows: 1

	   * - Desired Configuration
	     - Docker Name
	   * - PyTorch, CPU-only
	     - vitis-ai-pytorch-cpu
	   * - PyTorch, with ROCm acceleration
	     - vitis-ai-pytorch-rocm
	   * - PyTorch, with AI Optimizer and ROCm acceleration
	     - vitis-ai-opt-pytorch-rocm
	   * - TensorFlow 1.15, CPU-only
	     - vitis-ai-tensorflow-cpu
	   * - TensorFlow 2, CPU-only
	     - vitis-ai-tensorflow2-cpu
	   * - TensorFlow 2, with ROCm acceleration
	     - vitis-ai-tensorflow2-rocm
	   * - TensorFlow 2, with AI Optimizer and ROCm acceleration
	     - vitis-ai-opt-tensorflow2-rocm

	.. important:: The CPU-only containers *do not provide GPU acceleration support* which is **strongly recommended** for acceleration of the Vitis AI :ref:`Quantization process <quantization-process>`. The pre-built CPU-only containers should only be used when a GPU is not available on the host machine. The AI Optimizer containers are only required for :ref:`pruning <model-optimization>` and require a license.

#. Clone the Vitis AI repository::

	git clone https://github.com/Xilinx/Vitis-AI

#. Install the petalinux sdk cross-compilation tools. By default, the cross-compiler will be installed in ``~/petalinux_sdk_2022.2``. ::

	cd Vitis-AI/board_setup/vck190
	./host_cross_compiler_setup.sh

#. Download the pre-built Vitis AI board image for VCK190::

	wget https://www.xilinx.com/member/forms/download/design-license-xef.html?filename=xilinx-vck190-dpu-v2022.2-v3.0.0.img.gz

   **Note:** The pre-built Vitis AI board image includes the Vitis AI Runtime packages, VART samples, Vitis-AI-Library samples and models. The examples are pre-compiled. Therefore, you do not need to install Vitis AI Runtime packages and model package on the board separately. To install the Vitis AI Runtime and Vitis AI models on your own image, refer to these `instructions <https://docs.xilinx.com/r/en-US/ug1414-vitis-ai/Installing-Vitis-AI-Runtime-on-the-Evaluation-Board>`__.

#. Download and install Balena Etcher from https://etcher.io/ to burn the board image file onto the SD card.

#. Insert the imaged SD card into the target VCK190 board.

#. Connect the power adapter and boot the board using the serial port to interact with the target.

#. Configure the IP address and related settings for the board using the serial port.

|


*************************
Environment Setup
*************************

* The model development tools (quantization, compilation, etc...) are run within the Vitis AI docker container. To start the Vitis AI docker image, run the following command::

	cd <Vitis-AI install path>/Vitis-AI
	./docker_run.sh xilinx/<Docker Name>:latest


* The ARM cross-compiler is run on the host workstation (outside the docker container). To set up the environment for using the cross-compiler, source the following script in your terminal::

	source ~/petalinux_sdk_2022.2/environment-setup-cortexa72-cortexa53-xilinx-linux


|

****************************
Tensorflow Resnet50 Tutorial
****************************

This tutorial assumes that Vitis AI has been installed and that the VCK190 board has been configured, as explained in the installation instructions above.

#. Pull the pre-built Vitis AI docker container for TensorFlow 1.15, and launch the image::

	cd <Vitis-AI install path>/Vitis-AI
	docker pull xilinx/vitis-ai-tensorflow-cpu:latest
	./docker_run.sh xilinx/vitis-ai-tensorflow-cpu:latest

   **Note:** All subsequent steps of this tutorial are executed in the docker session.

#. Download the Resnet50 floating-point model from the Vitis AI model zoo::

	wget https://www.xilinx.com/bin/public/openDownload?filename=tf_resnetv1_50_imagenet_224_224_6.97G_3.0.zip -O tf_resnetv1_50_imagenet_224_224_6.97G_3.0.zip
	unzip tf_resnetv1_50_imagenet_224_224_6.97G_3.0.zip

#. Download the calibration images (the full dataset is from `ImageNet <http://image-net.org/download-images>`__)::

	wget https://www.xilinx.com/bin/public/openDownload?filename=Imagenet_calib.tar.gz -O Imagenet_calib.tar.gz
	tar -xzvf Imagenet_calib.tar.gz -C tf_resnetv1_50_imagenet_224_224_6.97G_3.0/data

#. Download the sample images used by the example application::

	cd /workspace/examples
	wget https://www.xilinx.com/bin/public/openDownload?filename=vitis_ai_runtime_r3.0.0_image_video.tar.gz -O vitis_ai_runtime_r3.0.0_image_video.tar.gz
	tar -xzvf vitis_ai_runtime_r3.0.0_image_video.tar.gz -C vai_runtime

#. Activate the Conda "vitis-ai-tensorflow" environment::

	conda activate vitis-ai-tensorflow

#. Configure the quantization process: edit the ``/workspace/tf_resnetv1_50_imagenet_224_224_6.97G_3.0/code/quantize/config.ini`` file and set the ``CALIB_BATCH_SIZE`` option to ``5``. 

#. Quantize the floating-point model::

	cd /workspace/tf_resnetv1_50_imagenet_224_224_6.97G_3.0/code/quantize
	bash quantize.sh

#. Compile the quantized model::

	cd /workspace/tf_resnetv1_50_imagenet_224_224_6.97G_3.0
	vai_c_tensorflow -f ./quantized/quantize_eval_model.pb -a /opt/vitis_ai/compiler/arch/DPUCVDX8H/VCK50008PE/arch.json -o ./compiled -n resnet50_tf

#. Cross-compile the example application (*details to be added*)
   Note: the example is already pre-compiled in the standard board image, but I feel it is important to show the cross-compilation steps as this is something people will have to do routinely.

#. Transfer compiled example to VCK190 board (*details to be added*)

#. Execute example (*details to be added*)


.. |trade|  unicode:: U+02122 .. TRADEMARK SIGN
   :ltrim:
.. |reg|    unicode:: U+000AE .. REGISTERED TRADEMARK SIGN
   :ltrim: