<table>
 <tr>
   <td align="center"><img src="https://www.xilinx.com/content/dam/xilinx/imgs/press/media-kits/corporate/xilinx-logo.png" width="30%"/><h1>Vitis AI</h1>
   </td>
 </tr>
</table>

Vitis AI is Xilinxâ€™s development stack for AI inference on Xilinx
hardware platforms, including both edge devices and Alveo cards.

It consists of optimized IP, tools, libraries, models, and example
designs. It is designed with high efficiency and ease of use in mind,
unleashing the full potential of AI acceleration on Xilinx FPGA and
ACAP.

[![Vitis AI architecture](images/Vitis-AI-arch.png)

Vitis AI is composed of the following key components:

-   AI Model Zoo - A comprehensive set of pre-optimized models that are
    ready to deploy on Xilinx devices.

-   AI Optimizer - An optional model optimizer that can prune a model by
    up to 90%. It is separately available with commercial licenses.

-   AI Quantizer - A powerful quantizer that supports model
    quantization, calibration, and fine tuning.

-   AI Compiler - Compiles the quantized model to a high-efficient
    instruction set and data flow.

-   AI Profiler - Perform an in-depth analysis of the efficiency and
    utilization of AI inference implementation.

-   AI Library - Offers high-level yet optimized C++ APIs for AI
    applications from edge to cloud.

-   DPU - Efficient and scalable IP cores can be customized to meet the
    needs for many different applications

For more details on the different DPUs available, see [DPU Naming](https://github.com/Xilinx/Vitis-AI/blob/master/docs/dpu_naming.md).

Learn More: [Vitis AI Overview](https://www.xilinx.com/products/design-tools/vitis/vitis-ai.html&gt;).
