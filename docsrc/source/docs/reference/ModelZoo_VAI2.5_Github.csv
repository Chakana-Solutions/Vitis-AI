,Task,Application,Framework,Name,FP32 Floating-Point Accuracy,Quantized Accuracy,Input Dims(HWC),Model Architecture,Source Paper,Dataset,Dataset URL,Multi-Task,Percentage Pruned,Ops (G),MLPerf?,,,,
,Classification,General,TensorFlow,tf_inceptionresnetv2_imagenet_299_299_26.35G_2.5,0.8037,0.7946,299*299*3,Inception-ResNet-v2,https://arxiv.org/abs/1602.07261,ILSVRC2012,https://www.image-net.org/download.php,,,26.35,,,,,
,Classification,General,TensorFlow,tf_inceptionv1_imagenet_224_224_3G_2.5,0.6976,0.6794,224*224*3,GoogleNetv1,https://arxiv.org/abs/1801.04381,ILSVRC2012,https://www.image-net.org/download.php,,,3,,,,,
,Classification,General,TensorFlow,tf_inceptionv2_imagenet_224_224_3.88G_2.5,0.7399,7331,224*224*3,Inception-v2,https://arxiv.org/abs/1512.00567,ILSVRC2012,https://www.image-net.org/download.php,,,3.88,,,,,
,Classification,General,TensorFlow,tf_inceptionv3_imagenet_299_299_11.45G_2.5?,0.7798,0.7735,299*299*3,Inception-v3,https://arxiv.org/abs/1512.00567,ILSVRC2012,https://www.image-net.org/download.php,,,11.45,,,,,
,Classification,General,TensorFlow,tf_inceptionv3_imagenet_299_299_0.2_9.1G_2.5?,0.7786,0.7668,299*299*3,Inception-v3,https://arxiv.org/abs/1512.00567,ILSVRC2012,https://www.image-net.org/download.php,,20.00%,9.1,,,,,
,Classification,General,TensorFlow,tf_inceptionv3_imagenet_299_299_0.4_6.9G_2.5?,0.7669,0.7561,299*299*3,Inception-v3,https://arxiv.org/abs/1512.00567,ILSVRC2012,https://www.image-net.org/download.php,,40.00%,6.9,,,,,
,Classification,General,TensorFlow,tf_inceptionv4_imagenet_299_299_24.55G_2.5,0.8018,0.7928,299*299*3,Inception-v4,https://arxiv.org/abs/1602.07261,ILSVRC2012,https://www.image-net.org/download.php,,,24.55,,,,,
,Classification,General,TensorFlow,tf_mobilenetv1_0.25_imagenet_128_128_27M_2.5,0.4144,0.3464,128*128*3,MobileNetV1,https://arxiv.org/abs/1704.04861,ILSVRC2012,https://www.image-net.org/download.php,,,0.027,,,,,
,Classification,General,TensorFlow,tf_mobilenetv1_0.5_imagenet_160_160_150M_2.5,0.5903,0.5195,160*160*3,MobileNetV1,https://arxiv.org/abs/1704.04861,ILSVRC2012,https://www.image-net.org/download.php,,,0.15,,,,,
,Classification,General,TensorFlow,tf_mobilenetv1_1.0_imagenet_224_224_1.14G_2.5?,0.7102,0.678,224*224*3,MobileNetV1,https://arxiv.org/abs/1704.04861,ILSVRC2012,https://www.image-net.org/download.php,,,1.14,,,,,
,Classification,General,TensorFlow,tf_mobilenetv1_1.0_imagenet_224_224_0.11_1.02G_2.5?,0.7056,0.6822,224*224*3,MobileNetV1,https://arxiv.org/abs/1704.04861,ILSVRC2012,https://www.image-net.org/download.php,,11.00%,0.11,,,,,
,Classification,General,TensorFlow,tf_mobilenetv1_1.0_imagenet_224_224_0.12_1G_2.5?,0.706,0.685,224*224*3,MobileNetV1,https://arxiv.org/abs/1704.04861,ILSVRC2012,https://www.image-net.org/download.php,,12.00%,0.12,,,,,
,Classification,General,TensorFlow,tf_mobilenetv2_1.0_imagenet_224_224_602M_2.5,0.7013,0.6767,224*224*3,MobileNetV2,https://arxiv.org/abs/1801.04381,ILSVRC2012,https://www.image-net.org/download.php,,,62,,,,,
,Classification,General,TensorFlow,tf_mobilenetv2_1.4_imagenet_224_224_1.16G_2.5,0.7411,0.7194,224*224*3,MobileNetV2,https://arxiv.org/abs/1801.04381,ILSVRC2012,https://www.image-net.org/download.php,,,1.16,,,,,
,Classification,General,TensorFlow,tf_resnetv1_50_imagenet_224_224_6.97G_2.5?,0.752,0.7436,224*224*3,ResNet50,https://arxiv.org/abs/1512.03385,ILSVRC2012,https://www.image-net.org/download.php,,,6.97,,,,,
,Classification,General,TensorFlow,tf_resnetv1_50_imagenet_224_224_0.38_4.3G_2.5?,0.7442,0.7375,224*224*3,ResNet50,https://arxiv.org/abs/1512.03385,ILSVRC2012,https://www.image-net.org/download.php,,38.00%,0.38,,,,,
,Classification,General,TensorFlow,tf_resnetv1_50_imagenet_224_224_0.65_2.45G_2.5?,0.7279,0.7167,224*224*3,ResNet50,https://arxiv.org/abs/1512.03385,ILSVRC2012,https://www.image-net.org/download.php,,65.00%,2.45,,,,,
,Classification,General,TensorFlow,tf_resnetv1_101_imagenet_224_224_14.4G_2.5,0.764,0.756,224*224*3,ResNet50,https://arxiv.org/abs/1512.03385,ILSVRC2012,https://www.image-net.org/download.php,,,14.4,,,,,
,Classification,General,TensorFlow,tf_resnetv1_152_imagenet_224_224_21.83G_2.5,0.7681,0.7463,224*224*3,ResNet50,https://arxiv.org/abs/1512.03385,ILSVRC2012,https://www.image-net.org/download.php,,,21.83,,,,,
,Classification,General,TensorFlow,tf_vgg16_imagenet_224_224_30.96G_2.5?,0.7089,0.7069,224*224*3,VGG16,https://arxiv.org/abs/1409.1556,ILSVRC2012,https://www.image-net.org/download.php,,,30.96,,,,,
,Classification,General,TensorFlow,tf_vgg16_imagenet_224_224_0.43_17.67G_2.5?,0.6929,0.6823,224*224*3,VGG16,https://arxiv.org/abs/1409.1556,ILSVRC2012,https://www.image-net.org/download.php,,43.00%,17.67,,,,,
,Classification,General,TensorFlow,tf_vgg16_imagenet_224_224_0.5_15.64G_2.5?,0.6857,0.6729,224*224*3,VGG16,https://arxiv.org/abs/1409.1556,ILSVRC2012,https://www.image-net.org/download.php,,50.00%,15.64,,,,,
,Classification,General,TensorFlow,tf_vgg19_imagenet_224_224_39.28G_2.5,0.71,0.7026,224*224*3,VGG19,https://arxiv.org/abs/1409.1556,ILSVRC2012,https://www.image-net.org/download.php,,,39.28,,,,,
,Classification,General,TensorFlow,tf_resnetv2_50_imagenet_299_299_13.1G_2.5,0.7559,0.7445,299*299*3,ResNet50V2,(https://arxiv.org/abs/1603.05027,ILSVRC2012,https://www.image-net.org/download.php,,,13.1,,,,,
,Classification,General,TensorFlow,tf_resnetv2_101_imagenet_299_299_26.78G_2.5,0.7695,0.7506,299*299*3,ResNet50V2,(https://arxiv.org/abs/1603.05027,ILSVRC2012,https://www.image-net.org/download.php,,,26.78,,,,,
,Classification,General,TensorFlow,tf_resnetv2_152_imagenet_299_299_40.47G_2.5,0.7779,0.7432,299*299*3,ResNet50V2,(https://arxiv.org/abs/1603.05027,ILSVRC2012,https://www.image-net.org/download.php,,,40.47,,,,,
,Classification,General,TensorFlow,tf_efficientnet-edgetpu-S_imagenet_224_224_4.72G_2.5,0.7702/0.9377,0.7660/0.9337,224*224*3,EfficientNet-EdgeTPU Small,https://arxiv.org/abs/2003.02838,ILSVRC2012,https://www.image-net.org/download.php,,,4.72,,,,,
,Classification,General,TensorFlow,tf_efficientnet-edgetpu-M_imagenet_240_240_7.34G_2.5,0.7862/0.9440,0.7798/0.9406,240*240*3,EfficientNet-EdgeTPU Medium,https://arxiv.org/abs/2003.02838,ILSVRC2012,https://www.image-net.org/download.php,,,7.34,,,,,
,Classification,General,TensorFlow,tf_efficientnet-edgetpu-L_imagenet_300_300_19.36G_2.5,0.8026/0.9514,0.7996/0.9491,300*300*3,EfficientNet-EdgeTPU Large,https://arxiv.org/abs/2003.02838,ILSVRC2012,https://www.image-net.org/download.php,,,19.36,,,,,
,Classification,General,TensorFlow,tf_mlperf_resnet50_imagenet_224_224_8.19G_2.5,0.7652,0.7606,224*224*3,ResNet50,https://arxiv.org/abs/1512.03385,ILSVRC2012,https://www.image-net.org/download.php,,,8.19,Y,,,,
,Classification,General,TensorFlow,tf_mobilenetEdge1.0_imagenet_224_224_990M_2.5,0.7227,0.6775,224*224*3,mobilenetEdge1.0,"No paper, based on TensorFlow model",ILSVRC2012,https://www.image-net.org/download.php,,,0.99,,,,,
,Classification,General,TensorFlow,tf_mobilenetEdge0.75_imagenet_224_224_624M_2.5,0.7201,0.6489,224*224*3,mobilenetEdge0.75,"No paper, based on TensorFlow model",ILSVRC2012,https://www.image-net.org/download.php,,,0.624,,,,,
,Classification,General,TensorFlow 2,tf2_resnet50_imagenet_224_224_7.76G_2.5,0.7513,0.7423,224*224*3,ResNet50,https://arxiv.org/abs/1512.03385,ILSVRC2012,https://www.image-net.org/download.php,,,7.76,,,,,
,Classification,General,TensorFlow 2,tf2_mobilenetv1_imagenet_224_224_1.15G_2.5,0.7005,0.5603,224*224*3,MobileNetV1,https://arxiv.org/abs/1704.04861,ILSVRC2012,https://www.image-net.org/download.php,,,1.15,,,,,
,Classification,General,TensorFlow 2,tf2_inceptionv3_imagenet_299_299_11.5G_2.5,0.7753,0.7694,299*299*3,Inception-v3,https://arxiv.org/abs/1512.00567,ILSVRC2012,https://www.image-net.org/download.php,,,11.5,,,,,
,Classification,General,TensorFlow 2,tf2_efficientnet-b0_imagenet_224_224_0.78G_2.5,0.7690/0.9320,0.7515/0.9273,224*224*3,EfficientNet-B0,https://arxiv.org/abs/1905.11946,ILSVRC2012,https://www.image-net.org/download.php,,78.00%,0.78,,,,,
,Classification,General,TensorFlow 2,tf2_mobilenetv3_imagenet_224_224_132M_2.5,0.6756/0.8728,0.6536/0.8544,224*224*3,MobileNetV3,https://arxiv.org/abs/1905.02244,ILSVRC2012,https://www.image-net.org/download.php,,,0.132,,,,,
,Classification,General,PyTorch,pt_inceptionv3_imagenet_299_299_11.4G_2.5?,0.775/0.936,0.771/0.935,299*299*3,Inception-v3,https://arxiv.org/abs/1512.00567,ILSVRC2012,https://www.image-net.org/download.php,,,11.4,,,,,
,Classification,General,PyTorch,pt_inceptionv3_imagenet_299_299_0.3_8G_2.5?,0.775/0.936,0.772/0.935,299*299*3,Inception-v3,https://arxiv.org/abs/1512.00567,ILSVRC2012,https://www.image-net.org/download.php,,30.00%,8,,,,,
,Classification,General,PyTorch,pt_inceptionv3_imagenet_299_299_0.4_6.8G_2.5?,0.768/0.931,0.764/0.929,299*299*3,Inception-v3,https://arxiv.org/abs/1512.00567,ILSVRC2012,https://www.image-net.org/download.php,,40.00%,6.8,,,,,
,Classification,General,PyTorch,pt_inceptionv3_imagenet_299_299_0.5_5.7G_2.5?,0.757/0.921,0.752/0.918,299*299*3,Inception-v3,https://arxiv.org/abs/1512.00567,ILSVRC2012,https://www.image-net.org/download.php,,50.00%,5.7,,,,,
,Classification,General,PyTorch,pt_inceptionv3_imagenet_299_299_0.6_4.5G_2.5?,0.739/0.911,0.732/0.908,299*299*3,Inception-v3,https://arxiv.org/abs/1512.00567,ILSVRC2012,https://www.image-net.org/download.php,,60.00%,4.5,,,,,
,Classification,General,PyTorch,pt_squeezenet_imagenet_224_224_703.5M_2.5,0.582/0.806,0.582/0.806,224*224*3,SqueezeNet,https://arxiv.org/abs/1602.07360,ILSVRC2012,https://www.image-net.org/download.php,,,0.7035,,,,,
,Classification,General,PyTorch,pt_resnet50_imagenet_224_224_8.2G_2.5?,0.761/0.929,0.760/0.928,224*224*3,ResNet50,https://arxiv.org/abs/1512.03385,ILSVRC2012,https://www.image-net.org/download.php,,,8.2,,,,,
,Classification,General,PyTorch,pt_resnet50_imagenet_224_224_0.3_5.8G_2.5?,0.760/0.929,0.757/0.928,224*224*3,ResNet50,https://arxiv.org/abs/1512.03385,ILSVRC2012,https://www.image-net.org/download.php,,30.00%,5.8,,,,,
,Classification,General,PyTorch,pt_resnet50_imagenet_224_224_0.4_4.9G_2.5?,0.755/0.926,0.752/0.925,224*224*3,ResNet50,https://arxiv.org/abs/1512.03385,ILSVRC2012,https://www.image-net.org/download.php,,40.00%,4.9,,,,,
,Classification,General,PyTorch,pt_resnet50_imagenet_224_224_0.5_4.1G_2.5?,0.748/0.921,0.745/0.920,224*224*3,ResNet50,https://arxiv.org/abs/1512.03385,ILSVRC2012,https://www.image-net.org/download.php,,50.00%,4.1,,,,,
,Classification,General,PyTorch,pt_resnet50_imagenet_224_224_0.6_3.3G_2.5?,0.742/0.917,0.738/0.915,224*224*3,ResNet50,https://arxiv.org/abs/1512.03385,ILSVRC2012,https://www.image-net.org/download.php,,60.00%,3.3,,,,,
,Classification,General,PyTorch,pt_resnet50_imagenet_224_224_0.7_2.5G_2.5?,0.726/0.908,0.720/0.906,224*224*3,ResNet50,https://arxiv.org/abs/1512.03385,ILSVRC2012,https://www.image-net.org/download.php,,70.00%,2.5,,,,,
,Classification,General,PyTorch,pt_OFA-resnet50_imagenet_224_224_15.0G_2.5?,0.799/0.948,0.789/0.944,224*224*3,ResNet50,https://arxiv.org/abs/1512.03385,ILSVRC2012,https://www.image-net.org/download.php,,,15,,,,,
,Classification,General,PyTorch,pt_OFA-resnet50_imagenet_224_224_0.45_8.2G_2.5?,0.795/0.945,0.784/0.941,224*224*3,ResNet50,https://arxiv.org/abs/1512.03385,ILSVRC2012,https://www.image-net.org/download.php,,45.00%,8.2,,,,,
,Classification,General,PyTorch,pt_OFA-resnet50_imagenet_224_224_0.60_6.0G_2.5?,0.791/0.943,0.780/0.939,224*224*3,ResNet50,https://arxiv.org/abs/1512.03385,ILSVRC2012,https://www.image-net.org/download.php,,60.00%,6,,,,,
,Classification,General,PyTorch,pt_OFA-resnet50_imagenet_192_192_0.74_3.6G_2.5?,0.777/0.937,0.770/0.933,192*192*3,ResNet50,https://arxiv.org/abs/1512.03385,ILSVRC2012,https://www.image-net.org/download.php,,74.00%,3.6,,,,,
,Classification,General,PyTorch,pt_OFA-resnet50_imagenet_160_160_0.88_1.8G_2.5?,0.752/0.918,0.744/0.918,160*160*3,ResNet50,https://arxiv.org/abs/1512.03385,ILSVRC2012,https://www.image-net.org/download.php,,88.00%,1.8,,,,,
,Classification,General,PyTorch,pt_OFA-depthwise-res50_imagenet_176_176_2.49G_2.5,0.7633/0.9292,0.7629/0.9306,176*176*3,ResNet50,https://arxiv.org/abs/1512.03385,ILSVRC2012,https://www.image-net.org/download.php,,,2.49,,,,,
,Classification,General,TensorFlow,tf_ViT_imagenet_352_352_21.3G_2.5,0.8282,0.8254,352*352*3,ViT,https://arxiv.org/abs/2010.11929,ILSVRC2012,https://www.image-net.org/download.php,,,21.3,,,,,
,Classification,Car type classification,PyTorch,pt_vehicle-type-classification_CompCars_224_224_3.63G_2.5,0.9025,0.9011,224*224*3,Custom AMD,Custom AMD,CompCars,http://mmlab.ie.cuhk.edu.hk/datasets/comp_cars/,,,3.63,,,,,
,Classification,Car make classification,PyTorch,pt_vehicle-make-classification_CompCars_224_224_3.63G_2.5,0.8991,0.8939,224*224*3,Custom AMD,Custom AMD,CompCars,http://mmlab.ie.cuhk.edu.hk/datasets/comp_cars/,,,3.63,,,,,
,Classification,Car color classification,PyTorch,pt_vehicle-color-classification_color_224_224_3.63G_2.5,0.9549,0.9549,224*224*3,Custom AMD,Custom AMD,Color-Chen,https://drive.google.com/file/d/1n8Ja6g5eO82mbRlsTXkdVXNMPpApLd5K/view,,,3.63,,,,,
,Detection,General,TensorFlow,tf_ssdmobilenetv1_coco_300_300_2.47G_2.5,0.208,0.21,300*300*3,SSD MobileNetV1,"No paper, based on TensorFlow model",COCO,https://cocodataset.org/,,,2.47,,,,,
,Detection,General,TensorFlow,tf_ssdmobilenetv2_coco_300_300_3.75G_2.5,0.215,0.211,300*300*3,SSD MobileNetV2,"No paper, based on TensorFlow model",COCO,https://cocodataset.org/,,,3.75,,,,,
,Detection,General,TensorFlow,tf_ssdresnet50v1_fpn_coco_640_640_178.4G_2.5,0.301,0.29,640*640*3,SSD ResNet50v1 FPN,https://arxiv.org/abs/1708.02002,COCO,https://cocodataset.org/,,,178.4,,,,,
,Detection,General,TensorFlow,tf_yolov3_voc_416_416_65.63G_2.5,0.7846,0.7744,416*416*3,YOLOv3,https://arxiv.org/abs/1804.02767,VOC2012,http://host.robots.ox.ac.uk/pascal/VOC/voc2012/,,,65.63,,,,,
,Detection,General,TensorFlow,tf_mlperf_resnet34_coco_1200_1200_433G_2.5,0.225,0.215,1200*1200*3,ResNet34,https://arxiv.org/abs/1512.03385,COCO,https://cocodataset.org/,,,433,Y,,,,
,Detection,General,TensorFlow,tf_ssdlite_mobilenetv2_coco_300_300_1.5G_2.5,0.217,0.209,300*300*3,SSDLite MobileNetV2,"No paper, based on TensorFlow model",COCO,https://cocodataset.org/,,,1.5,,,,,
,Detection,General,TensorFlow,tf_ssdinceptionv2_coco_300_300_9.62G_2.5,0.239,0.236,300*300*3,SSD inception-v2,"No paper, based on TensorFlow model",COCO,https://cocodataset.org/,,,9.62,,,,,
,Detection,General,TensorFlow,tf_refinedet_VOC_320_320_81.9G_2.5,0.8015,0.7999,320*320*3,RefineDet,https://arxiv.org/abs/1711.06897,VOC2012,http://host.robots.ox.ac.uk/pascal/VOC/voc2012/,,,81.9,,,,,
,Detection,General,TensorFlow,tf_efficientdet-d2_coco_768_768_11.06G_2.5,0.413,0.327,768*768*3,EfficientDet-d2,https://arxiv.org/abs/1911.09070,COCO,https://cocodataset.org/,,,11.06,,,,,
,Detection,General,TensorFlow 2,tf2_yolov3_coco_416_416_65.9G_2.5,0.377,0.331,416*416*3,YOLOv3,https://arxiv.org/abs/1804.02767,COCO,https://cocodataset.org/,,,65.9,,,,,
,Detection,General,TensorFlow,tf_yolov4_coco_416_416_60.3G_2.5,0.477,0.393,416*416*3,YOLOv4,https://arxiv.org/abs/2004.10934,COCO,https://cocodataset.org/,,,60.3,,,,,
,Detection,General,TensorFlow,tf_yolov4_coco_512_512_91.2G_2.5,0.487,0.412,512*512*3,YOLOv4,https://arxiv.org/abs/2004.10934,COCO,https://cocodataset.org/,,,91.2,,,,,
,Detection,General,PyTorch,pt_OFA-yolo_coco_640_640_48.88G_2.5,0.436,0.421,640*640*3,OFA-YOLO,,COCO,https://cocodataset.org/,,,48.88,,,,,
,Detection,General,PyTorch,pt_OFA-yolo_coco_640_640_0.3_34.72G_2.5,0.42,0.401,640*640*3,OFA-YOLO,,COCO,https://cocodataset.org/,,30.00%,34.72,,,,,
,Detection,General,PyTorch,pt_OFA-yolo_coco_640_640_0.5_24.62G_2.5,0.392,0.378,640*640*3,OFA-YOLO,,COCO,https://cocodataset.org/,,50.00%,24.62,,,,,
,Detection,Medical Detection,TensorFlow,tf_RefineDet-Medical_EDD_320_320_81.28G_2.5?,0.7866,0.7857,320*320*3,RefineDet,https://arxiv.org/abs/1711.06897,EDD2020,https://github.com/nizamphoenix/EDD2020,,,81.28,,,,,
,Detection,Medical Detection,TensorFlow,tf_RefineDet-Medical_EDD_320_320_0.5_41.42G_2.5?,0.7798,0.7772,320*320*3,RefineDet,https://arxiv.org/abs/1711.06897,EDD2020,https://github.com/nizamphoenix/EDD2020,,50.00%,41.42,,,,,
,Detection,Medical Detection,TensorFlow,tf_RefineDet-Medical_EDD_320_320_0.75_20.54G_2.5?,0.7885,0.7826,320*320*3,RefineDet,https://arxiv.org/abs/1711.06897,EDD2020,https://github.com/nizamphoenix/EDD2020,,75.00%,20.54,,,,,
,Detection,Medical Detection,TensorFlow,tf_RefineDet-Medical_EDD_320_320_0.85_12.32G_2.5?,0.7898,0.7877,320*320*3,RefineDet,https://arxiv.org/abs/1711.06897,EDD2020,https://github.com/nizamphoenix/EDD2020,,85.00%,12.32,,,,,
,Detection,Medical Detection,TensorFlow,tf_RefineDet-Medical_EDD_320_320_0.88_9.83G_2.5?,0.7839,0.8002,320*320*3,RefineDet,https://arxiv.org/abs/1711.06897,EDD2020,https://github.com/nizamphoenix/EDD2020,,88.00%,9.83,,,,,
,Detection,ADAS Traffic sign Detection,PyTorch,pt_yolox_TT100K_640_640_73G_2.5,0.623,0.621,640*640*3,YOLOX,https://arxiv.org/abs/2107.08430,TT100K,https://cg.cs.tsinghua.edu.cn/traffic-sign/,,,73,,,,,
,Detection,ADAS Lane Detection,PyTorch,pt_ultrafast_CULane_288_800_8.4G_2.5,0.6988,0.6922,288*800*3,Ultra-Fast,https://arxiv.org/abs/2004.11757,CULane,https://xingangpan.github.io/projects/CULane.html,,,8.4,,,,,
,Detection,ADAS 3D Detection,PyTorch,pt_pointpillars_kitti_12000_100_10.8G_2.5,"Car 3D AP@0.5(easy, moderate, hard)","Car 3D AP@0.5(easy, moderate, hard)",12000*100*4,PointPillars,https://arxiv.org/abs/1812.05784,Kitti,http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d,,,10.8,,,,,
,,,,,"90.79, 89.66, 88.78","90.75, 87.04, 83.44",,,,,,,,,,,,,
,Detection,ADAS Surround-view 3D Detection,PyTorch,pt_pointpillars_nuscenes_40000_64_108G_2.5,mAP: 42.2,mAP: 40.5,40000*64*5,PointPillars,https://arxiv.org/abs/1812.05784,Nuscenes,https://www.nuscenes.org/,,,108,,,,,
,,,,,NDS: 55.1,NDS: 53.0,,,,,,,,,,,,,
,Detection,ADAS 4D radar based 3D Detection,PyTorch,pt_centerpoint_astyx_2560_40_54G_2.5,BEV AP@0.5: 32.84,BEV AP@0.5: 33.82,2560*40*4,CenterPoint,https://arxiv.org/abs/2006.11275,Astyx,https://github.com/azinke/astyx,,,54,,,,,
,,,,,3D AP@0.5: 28.27,3D AP@0.5: 18.54(QAT),,,,,,,,,,,,,
,Detection,ADAS Image-lidar fusion based 3D Detection,PyTorch,pt_CLOCs_kitti_2.5,2d detection: Mod Car bbox AP@0.70: 89.40,2d detection: Mod Car bbox AP@0.70: 89.50,2d detection (YOLOX): 384*1248*3,CLOCs,https://arxiv.org/abs/2009.00784,Kitti,http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d,,,,,,,,
,,,,,3d detection: Mod Car bev@0.7 :85.50,3d detection: Mod Car bev@0.7 :85.50,3d detection (PointPillars): 12000*100*4,,,,,,,,,,,,
,,,,,Mod Car 3d@0.7 :70.01,Mod Car 3d@0.7 :70.01,fusionnet: 800*1000*4,,,,,,,,,,,,
,,,,,Mod Car bev@0.5 :89.69,Mod Car bev@0.5 :89.69,,,,,,,,,,,,,
,,,,,Mod Car 3d@0.5 :89.48,Mod Car 3d@0.5 :89.48,,,,,,,,,,,,,
,,,,,fusionnet: Mod Car bev@0.7 :87.58,fusionnet: Mod Car bev@0.7 :87.58,,,,,,,,,,,,,
,,,,,Mod Car 3d@0.7 :73.04,Mod Car 3d@0.7 :73.04,,,,,,,,,,,,,
,,,,,Mod Car bev@0.5 :93.98,Mod Car bev@0.5 :93.98,,,,,,,,,,,,,
,,,,,Mod Car 3d@0.5 :93.56,Mod Car 3d@0.5 :93.56,,,,,,,,,,,,,
,Detection,ADAS Image-lidar sensor fusion Detection & Segmentation,PyTorch,pt_pointpainting_nuscenes_126G_2.5,mIoU: 69.1,mIoU: 68.6,semanticfpn:320*576*3,PointPainting,https://arxiv.org/abs/1911.10150,Nuscenes,https://www.nuscenes.org/,,,126,,,,,
,,,,,mAP: 51.8,mAP: 50.4,pointpillars:40000*64*16,,,,,,,,,,,,
,,,,,NDS: 58.7,NDS: 56.4,,,,,,,,,,,,,
,Detection,ADAS Multi Task,PyTorch,pt_MT-resnet18_mixed_320_512_13.65G_2.5,mAP:39.51,mAP:38.41,320*512*3,ResNet18,https://arxiv.org/abs/1512.03385,"Cityscapes
BDD100K","https://www.cityscapes-dataset.com/
https://www.bdd100k.com/",Y,,13.65,,,,,
,,,,,mIOU:44.03,mIOU:42.71,,,,,,,,,,,,,
,Detection,ADAS Multi Task,PyTorch,pt_multitaskv3_mixed_320_512_25.44G_2.5,mAP:51.2,mAP:50.9,320*512*3,AMD Custom,AMD Custom,"Cityscapes
BDD100K
KITTI","https://www.cityscapes-dataset.com/
https://www.bdd100k.com/
http://www.cvlibs.net/datasets/kitti/
",Y,,25.44,,,,,
,,,,,mIOU:58.14,mIOU:57.52,,,,,,,,,,,,,
,,,,,Drivable mIOU: 82.57,Drivable mIOU: 82.30,,,,,,,,,,,,,
,,,,,Lane IOU:43.71,Lane IOU:44.01,,,,,,,,,,,,,
,,,,,Silog: 8.78,Silog: 9.32,,,,,,,,,,,,,
,Segmentation,ADAS 2D Segmentation,PyTorch,pt_ENet_cityscapes_512_1024_8.6G_2.5,0.6442,0.6315,512*1024*3,Enet,https://arxiv.org/abs/1606.02147,Cityscapes,https://www.cityscapes-dataset.com/,,,8.6,,,,,
,Segmentation,ADAS 2D Segmentation,PyTorch,pt_SemanticFPN-resnet18_cityscapes_256_512_10G_2.5,0.629,0.623,256*512*3,SemanticFPN,https://arxiv.org/abs/1901.02446,Cityscapes,https://www.cityscapes-dataset.com/,,,10,,,,,
,Segmentation,ADAS 2D Segmentation,PyTorch,pt_SemanticFPN-mobilenetv2_cityscapes_512_1024_5.4G_2.5,0.687,0.682,512*1024*3,SemanticFPN,https://arxiv.org/abs/1901.02446,Cityscapes,https://www.cityscapes-dataset.com/,,,5.4,,,,,
,Segmentation,ADAS 3D Point Cloud Segmentation,PyTorch,pt_salsanext_semantic-kitti_64_2048_0.6_20.4G_2.5,Acc avg 0.8860,Acc avg 0.8350,64*2048*3,SalsaNext,https://arxiv.org/abs/2003.03653,KITTI,http://www.cvlibs.net/datasets/kitti/,,,20.4,,,,,
,,,,,IoU avg 0.5100,IoU avg 0.4540,,,,,,,60.00%,20.4,,,,,
,Segmentation,ADAS 3D Point Cloud Segmentation,PyTorch,pt_salsanextv2_semantic-kitti_64_2048_0.75_32G_2.5,mIou: 54.2%,mIou: 54.2%,64*2048*5,SalsaNextv2,https://arxiv.org/abs/2003.03653,KITTI,http://www.cvlibs.net/datasets/kitti/,,,0.75,,,,,
,Segmentation,ADAS Instance Segmentation,PyTorch,pt_SOLO_coco_640_640_107G_2.5,0.242,0.212,640*640*3,SOLO,https://arxiv.org/abs/1912.04488,COCO,https://cocodataset.org/,,,107,,,,,
,Segmentation,ADAS 2D Segmentation,TensorFlow,tf_mobilenetv2_cityscapes_1024_2048_132.74G_2.5,0.6263,0.4578,1024*2048*3,MobileNetv2,https://arxiv.org/abs/1801.04381,Cityscapes,https://www.cityscapes-dataset.com/,,,132.74,,,,,
,Segmentation,ADAS 2D Segmentation,TensorFlow 2,tf2_erfnet_cityscapes_512_1024_54G_2.5,0.5298,0.5167,512*1024*3,ERFNet,http://www.robesafe.uah.es/personal/eduardo.romera/pdfs/Romera17tits.pdf,Cityscapes,https://www.cityscapes-dataset.com/,,,54,,,,,
,Segmentation,Medical Cell Nuclear Segmentation,TensorFlow 2,tf2_2d-unet_nuclei_128_128_5.31G_2.5,0.3968,0.3968,128*128*3,Unet,https://arxiv.org/abs/1505.04597,Nuclei,https://www.kaggle.com/code/advaitsave/tensorflow-2-nuclei-segmentation-unet/notebook,,,5.31,,,,,
,Segmentation,Medical Covid-19 Segmentation,PyTorch,pt_FPN-resnet18_covid19-seg_352_352_22.7G_2.5,2-classes Dice:0.8588,2-classes Dice:0.8547,352*352*3,AMD Custom,AMD Custom,COVID19-seg,https://drive.google.com/file/d/1bbKAqUuk7Y1q3xsDSwP07oOXN_GL3SQM/view,,,22.7,,,,,
,,,,,3-classes mIoU:0.5989,3-classes mIoU:0.5957,,,,,,,,,,,,,
,Segmentation,Medical CT lung Segmentation,PyTorch,pt_unet_chaos-CT_512_512_23.3G_2.5,Dice:0.9758,Dice:0.9747,512*512*3,Unet,https://arxiv.org/abs/1505.04597,CHAOS,https://chaos.grand-challenge.org/,,,23.3,,,,,
,Segmentation,Medical Polyp Segmentation,PyTorch,pt_HardNet_mixed_352_352_22.78G_2.5,mDice=0.9142,mDice=0.9136,352*352*3,HarDNet,https://arxiv.org/abs/1705.10872,"Kvasir-SEG, CVC-ColonDB, EndoScene, ETIS-Larib Polyp DB and CVC-Clinic DB","https://drive.google.com/file/d/1o8OfBvYE6K-EpDyvzsmMPndnUMwb540R/view?usp=sharing
https://drive.google.com/file/d/1lODorfB33jbd-im-qrtUgWnZXxB94F55/view?usp=sharing",,,22.78,,,,,
,Segmentation,RGB-D Segmentation,PyTorch,pt_sa-gate_NYUv2_360_360_178G_2.5,miou: 47.58%,miou: 46.80%,360*360*3,SA-Gate,https://arxiv.org/abs/2007.09183,NYUv2,https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html,,,178,,,,,
,NLP,Question and Answering,TensorFlow,tf_bert-base_SQuAD_128_22.34G_2.5,0.8694,0.8656,128,BERT,https://arxiv.org/abs/1810.04805,SQuAD,https://rajpurkar.github.io/SQuAD-explorer/,,,22.34,,,,,
,NLP,Sentiment Detection,TensorFlow 2,tf2_sentiment-detection_IMDB_500_32_53.3M_2.5,0.8708,0.8695,500*32,BERT,https://arxiv.org/abs/1810.04805,IMDB,"https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json
https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz",,,53.3,,,,,
,NLP,Customer Satisfaction Assessment,TensorFlow 2,tf2_customer-satisfaction_Cars4U_25_32_2.7M_2.5,0.9565,0.9565,25*32,BERT,https://arxiv.org/abs/1810.04805,Cars4U,https://www.kaggle.com/datasets/sukhmanibedi/cars4u,,,0.0027,,,,,
,NLP,Open Information Extraction,PyTorch,pt_open-information-extraction_qasrl_100_200_1.5G_2.5,Acc/F1-score:,Acc/F1-score:,100*200,BERT,https://arxiv.org/abs/1810.04805,qasrl,https://qasrl.org/,,,1.5,,,,,
,,,,,58.70%/77.12%,58.70%/77.19%,,,,,,,,,,,,,
,OCR,Text Detection,PyTorch,pt_textmountain_ICDAR_960_960_575.2G_2.5,0.8863,0.8851,960*960,TextMountain,https://arxiv.org/abs/1811.12786,"ICDAR2013
ICDAR2017","https://rrc.cvc.uab.es/?ch=8&com=introduction
https://rrc.cvc.uab.es/?ch=2",,,575.2,,,,,
,OCR,E2E OCR,PyTorch,pt_OCR_ICDAR2015_960_960_875G_2.5,0.6758,0.6776,960*960,ResNet34,https://arxiv.org/abs/1512.03385,ICDAR2015,https://iapr.org/archives/icdar2015/index.html%3Fp=254.html,,,875,,,,,
,Surveillance,Face Recognition,PyTorch,pt_facerec-resnet20_mixed_112_96_3.5G_2.5,0.9955,0.9947,112*96*3,ResNet20,https://arxiv.org/abs/1512.03385,Proprietary,Proprietary,,,3.5,,,,,
,Surveillance,Face Quality,PyTorch,pt_face-quality_80_60_61.68M_2.5,0.1233,0.1258,80*60*3,AMD Custom,AMD Custom,Proprietary,Proprietary,,,0.6168,,,,,
,Surveillance,Face ReID,PyTorch,pt_facereid-large_96_96_515M_2.5,mAP:0.794 Rank1:0.955,mAP:0.790 Rank1:0.953,96*96*3,ResNet18,https://arxiv.org/abs/1512.03385,Proprietary,Proprietary,,,0.515,,,,,
,Surveillance,Face ReID,PyTorch,pt_facereid-small_80_80_90M_2.5,mAP:0.560 Rank1:0.865,mAP:0.559 Rank1:0.865,80*80*3,ResNet18,https://arxiv.org/abs/1512.03385,Proprietary,Proprietary,,,0.9,,,,,
,Surveillance,ReID,PyTorch,pt_personreid-res18_market1501_176_80_1.1G_2.5,mAP:0.753 Rank1:0.898,mAP:0.746 Rank1:0.893,176*80*3,ResNet18 Backbone + Feature Extraction,AMD Custom,Market1501,https://zheng-lab.cecs.anu.edu.au/Project/project_reid.html,,,1.1,,,,,
,Surveillance,ReID,PyTorch,pt_personreid-res50_market1501_256_128_5.3G_2.5?,mAP:0.866 Rank1:0.951,mAP:0.869 Rank1:0.948,256*128*3,ResNet50 Backbone + Feature Extraction,AMD Custom,Market1501,https://zheng-lab.cecs.anu.edu.au/Project/project_reid.html,,,5.3,,,,,
,Surveillance,ReID,PyTorch,pt_personreid-res50_market1501_256_128_0.4_3.3G_2.5?,mAP:0.869 Rank1:0.948,mAP:0.869 Rank1:0.948,256*128*3,ResNet50 Backbone + Feature Extraction,AMD Custom,Market1501,https://zheng-lab.cecs.anu.edu.au/Project/project_reid.html,,,3.3,,,,,
,Surveillance,ReID,PyTorch,pt_personreid-res50_market1501_256_128_0.5_2.7G_2.5?,mAP:0.864 Rank1:0.944,mAP:0.864 Rank1:0.944,256*128*3,ResNet50 Backbone + Feature Extraction,AMD Custom,Market1501,https://zheng-lab.cecs.anu.edu.au/Project/project_reid.html,,,2.7,,,,,
,Surveillance,ReID,PyTorch,pt_personreid-res50_market1501_256_128_0.6_2.1G_2.5?,mAP:0.863 Rank1:0.946,mAP:0.859 Rank1:0.942,256*128*3,ResNet50 Backbone + Feature Extraction,AMD Custom,Market1501,https://zheng-lab.cecs.anu.edu.au/Project/project_reid.html,,,2.1,,,,,
,Surveillance,ReID,PyTorch,pt_personreid-res50_market1501_256_128_0.7_1.6G_2.5?,mAP:0.850 Rank1:0.940,mAP:0.848 Rank1:0.938,256*128*3,ResNet50 Backbone + Feature Extraction,AMD Custom,Market1501,https://zheng-lab.cecs.anu.edu.au/Project/project_reid.html,,,1.6,,,,,
,Surveillance,Person orientation estimation,PyTorch,pt_person-orientation_224_112_558M_2.5,0.93,0.929,224*112*3,Custom ResNet ,https://arxiv.org/abs/1512.03385,Proprietary,Proprietary,,,0.558,,,,,
,Surveillance,Joint detection and Tracking,PyTorch,pt_FairMOT_mixed_640_480_0.5_36G_2.5,MOTA 59.1%,MOTA 58.1%,640*480*3,FairMOT,https://arxiv.org/abs/2004.01888,"MOT17, Caltech, CityPerson Pedestrians, CUHKSYSU, PRW, ETH",https://github.com/Zhongdao/Towards-Realtime-MOT/blob/master/DATASET_ZOO.md,,50.00%,36,,,,,
,,,,,IDF1 62.5%,IDF1 60.5%,,,,,,,,,,,,,
,Surveillance,Crowd Counting,PyTorch,pt_BCC_shanghaitech_800_1000_268.9G_2.5,MAE: 65.83,MAE: 67.60,800*1000*3,BCC,https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Zhang_Single-Image_Crowd_Counting_CVPR_2016_paper,Shanghai Tech Campus,https://svip-lab.github.io/dataset/campus_dataset.html,,,268.9,,,,,
,,,,,MSE: 111.75,MSE: 117.36,,,,,,,,,,,,,
,Surveillance,Face Mask Detection,PyTorch,pt_face-mask-detection_512_512_0.59G_2.5,0.886,0.881,512*512*3,Yolo-fastest,http://doi.org/10.5281/zenodo.5131532,mask-detector,https://github.com/waittim/mask-detector/tree/master/modeling/data,,,0.59,,,,,
,Surveillance,Pose Estimation,PyTorch,pt_movenet_coco_192_192_0.5G_2.5,0.7972,0.7984,192*192*3,MoveNet,https://arxiv.org/abs/2105.04154,COCO,https://cocodataset.org/,,,0.5,,,,,
,Industrial Vision / Robotics,Depth Estimation,PyTorch,pt_fadnet_sceneflow_576_960_441G_2.5,EPE: 0.926,EPE: 1.169,576*960*3,FADNet,https://arxiv.org/abs/2003.10758,Sceneflow,https://lmb.informatik.uni-freiburg.de/resources/datasets/SceneFlowDatasets.en.html,,,441,,,,,
,Industrial Vision / Robotics,Binocular depth estimation,PyTorch,pt_fadnet_sceneflow_576_960_0.65_154G_2.5,EPE: 0.823,EPE: 1.158,576*960*3,FADNet,https://arxiv.org/abs/2003.10758,Sceneflow,https://lmb.informatik.uni-freiburg.de/resources/datasets/SceneFlowDatasets.en.html,,,0.65,,,,,
,Industrial Vision / Robotics,Binocular depth estimation,PyTorch,pt_psmnet_sceneflow_576_960_0.68_696G_2.5,EPE: 0.961,EPE: 1.022,576*960*3,PSMNet,https://arxiv.org/abs/1803.08669,Sceneflow,https://lmb.informatik.uni-freiburg.de/resources/datasets/SceneFlowDatasets.en.html,,,0.68,,,,,
,Industrial Vision / Robotics,Production Recognition,PyTorch,pt_pmg_rp2k_224_224_2.28G_2.5,0.964,0.9618,224*224*3,PMG,https://arxiv.org/abs/2003.03836,RP2K,"Website removed, perhaps email  Jingtian Peng (pjt@pinlandata.com)",,,2.28,,,,,
,Industrial Vision / Robotics,Interest Point Detection and Description,TensorFlow,tf_superpoint_mixed_480_640_52.4G_2.5,83.4 (thr=3),84.3 (thr=3),480*640*3,SuperPoint,https://arxiv.org/abs/2107.03601,COCO 2014,https://cocodataset.org/#download,,,52.4,,,,,
,Industrial Vision / Robotics,Hierarchical Localization,TensorFlow,tf_HFNet_mixed_960_960_20.09G_2.5,Day: 76.2/83.6/90.0,Day: 74.2/82.4/89.2,960*960*3,HFNet,https://arxiv.org/abs/1812.03506,Aachen - RobotCar Seasons - CMU Seasons - HPatches - SfM - Google Landmarks - Berkeley Deep Drive,https://github.com/ethz-asl/hfnet/blob/master/doc/datasets.md,,,20.09,,,,,
,,,,,Night: 58.2/68.4/80.6,Night: 54.1/66.3/73.5,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
