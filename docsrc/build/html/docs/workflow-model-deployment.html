<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
<!-- OneTrust Cookies Consent Notice start for xilinx.github.io -->

<script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="03af8d57-0a04-47a6-8f10-322fa00d8fc7" ></script>
<script type="text/javascript">
function OptanonWrapper() { }
</script>
<!-- OneTrust Cookies Consent Notice end for xilinx.github.io -->
  <title>Deploying a Model &mdash; Vitis AI 3.0 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/contentui.css" type="text/css" />
      <link rel="stylesheet" href="../_static/_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/contentui.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Toolchain Integration" href="workflow-system-integration.html" />
    <link rel="prev" title="Developing a Model" href="workflow-model-development.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
            <a href="../index.html" class="icon icon-home"> Vitis AI
            <img src="../_static/xilinx-header-logo.svg" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                3.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Vitis AI Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="workflow.html">Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Release Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="reference/release_notes_3.0.html">Release Notes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="reference/system_requirements.html">System Requirements</a></li>
<li class="toctree-l1"><a class="reference internal" href="install/install.html">Host Install Instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="board_setup/board_setup.html">Target Setup Instructions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Development</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="workflow-model-development.html">Model Development</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Deployment</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Model Deployment</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#workflow-for-deploying-a-model">Workflow for Deploying a Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#embedded-versus-data-center-workflows">Embedded versus Data Center Workflows</a></li>
<li class="toctree-l2"><a class="reference internal" href="#vitis-ai-library">Vitis AI Library</a></li>
<li class="toctree-l2"><a class="reference internal" href="#vitis-ai-runtime">Vitis AI Runtime</a></li>
<li class="toctree-l2"><a class="reference internal" href="#whole-application-acceleration">Whole Application Acceleration</a></li>
<li class="toctree-l2"><a class="reference internal" href="#vitis-ai-profiler">Vitis AI Profiler</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">System Integration</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="workflow-system-integration.html">System Integration</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Third-Party Tools</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="workflow-third-party.html">Third-Party Tools</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Zoo</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="workflow-model-zoo.html">Model Zoo</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Release Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="reference/release_documentation.html">Release Documentation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Vitis AI Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/Xilinx/Vitis-AI-Tutorials">Tutorials</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Related Tools</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/inference-server/">Inference Server</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/VVAS/">Vitis Video Analytics SDK</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/finn/">FINN / Brevitas</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/Xilinx/DPU-PYNQ">DPU-PYNQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Resources and Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="reference/additional_resources.html">Technical Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="reference/additional_resources.html#additional-resources">Additional Resources</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="reference/faq.html">FAQ</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: black" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Vitis AI</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Deploying a Model</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/docs/workflow-model-deployment.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="deploying-a-model">
<h1>Deploying a Model<a class="headerlink" href="#deploying-a-model" title="Permalink to this heading">¶</a></h1>
<section id="workflow-for-deploying-a-model">
<h2>Workflow for Deploying a Model<a class="headerlink" href="#workflow-for-deploying-a-model" title="Permalink to this heading">¶</a></h2>
<p>Once you have successfully quantized and compiled your model for a specific DPU, the next task is to deploy that model on the target. Follow these steps in this process:</p>
<p><strong>[Step 1]</strong> Test your model and application software on one of the Xilinx platforms for which a pre-built DPU image is provided. Ideally this would be the platform and DPU which most closely matches your final production deployment.</p>
<p><strong>[Step 2]</strong> Customize the Xilinx platform design with any substantive changes required to the DPU IP, and if possible to incorporate the pre/post processing pipeline acceleration components of your final pipeline. Retest your model.</p>
<p><strong>[Step 3]</strong> Port the Xilinx platform design to your final target hardware platform. Retest your model.</p>
<p>The motivation for this multi-step process is to minimize the number of variables involved in the initial deployment. This process enables the developer to perform verification at each stage. This has been found to save users many hours of frustration and troubleshooting.</p>
<p>In general, the workflow illustrated on the right-hand side of the following diagram is all that is required for the first two steps of deployment. Generally, the platform development component on the left-hand side of the diagram is only required for the third and final step. Part of the convenience of this is that the work can be partitioned between hardware developers and data science teams, enabling the hardware and data science teams to work in parallel, converging at the final step for the deployment on a custom hardware platform. The following image is representative for Vitis designs, but the ability to partition the effort is similar for Vivado designs. refer to the user
documentation for the <a class="reference internal" href="workflow-system-integration.html#vivado-integration"><span class="std std-ref">Vivado</span></a> and <a class="reference internal" href="workflow-system-integration.html#vitis-integration"><span class="std std-ref">Vitis</span></a> workflows for additional details of the hardware platform development workflow.</p>
<img alt="../_images/deployment_workflow.PNG" src="../_images/deployment_workflow.PNG" />
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Not captured in this image is the PetaLinux workflow. In the context of Xilinx™ pre-built target board images, the goal is to enable the developer without requiring that they modify Linux. An important exception to this is for developers who are customizing hardware IP and peripherals that reside within the memory space of the target CPU/APU and who wish to customize Linux. Also, in some circumstances, it is possible to directly install Vitis AI on the target without rebuilding the kernel image. Refer to <a class="reference internal" href="workflow-system-integration.html#linux-dpu-recipes"><span class="std std-ref">Linux DPU Recipes</span></a> for additional information.</p>
</div>
<p>An example that illustrates how to quantize, compile, and deploy models on the Alveo™ U200 and U250 Data Center Accelerator Cards, is available <a class="reference external" href="https://gitenterprise.xilinx.com/quentonh/vitis-ai-staging/tree/master/examples/alveo">here</a>.</p>
</section>
<section id="embedded-versus-data-center-workflows">
<h2>Embedded versus Data Center Workflows<a class="headerlink" href="#embedded-versus-data-center-workflows" title="Permalink to this heading">¶</a></h2>
<p>The Vitis AI workflow is largely unified for Embedded and Data Center applications but diverges at the deployment stage. There are various reasons for this divergence, including the following:</p>
<ul class="simple">
<li><p>Zynq® Ultrascale+™, Kria™, and Versal® SoC applications leverage the on-chip processor subsystem (APU) as the host control node for model deployment. It is important to consider optimization and <a class="reference external" href="#whole-application-acceleration">acceleration</a> of subgraphs that are deployed on the SoC APU.</p></li>
<li><p>Alveo data center card deployments leverage the AMD64 architecture host for execution of subgraphs that cannot be deployed on the DPU.</p></li>
<li><p>Zynq Ultrascale+ and Kria designs can leverage the DPU with either the Vivado workflow or the Vitis workflow.</p></li>
<li><p>Zynq Ultrascale+ and Kria designs built in Vivado do not use XRT.</p></li>
<li><p>All Vitis designs require the use of XRT.</p></li>
</ul>
</section>
<section id="vitis-ai-library">
<h2>Vitis AI Library<a class="headerlink" href="#vitis-ai-library" title="Permalink to this heading">¶</a></h2>
<p>The Vitis AI Library provides you with a head-start on model deployment. While it is possible for developers to directly leverage the Vitis AI Runtime APIs to deploy a model on Xilinx platforms, it is often more beneficial to start with a ready-made example that incorporates the various elements of a typical application, including:</p>
<ul class="simple">
<li><p>Simplified CPU-based pre- and post-processing implementations</p></li>
<li><p>Vitis AI Runtime integration at an application level</p></li>
</ul>
<p>Ultimately most developers will choose one of two paths for production:</p>
<ul class="simple">
<li><p>Directly leverage the VART APIs in their application code</p></li>
<li><p>Leverage the VAI Library as a starting point to code their application</p></li>
</ul>
<p>An advantage of leveraging the Vitis AI Library is ease-of-use, while the potential downsides include losing yourself in code that wasn’t intended for your specific use case, and also a lack of recognition on the part of the developer that the pre- and post-processing implementations provided by the Vitis AI Library will not be optimized for <a class="reference internal" href="#whole-application-acceleration"><span class="std std-ref">Whole Application Acceleration</span></a>.</p>
<p>If you prefer to use the Vitis AI Runtime APIs directly, many of the code examples provided in the <a class="reference external" href="https://github.com/Xilinx/Vitis-AI-Tutorials">Vitis AI
Tutorials</a> will offer an excellent starting point.</p>
<ul class="simple">
<li><p>For more information on Vitis AI Libraries, refer to the <em>Vitis AI Library User Guide</em>
(<a class="reference external" href="https://docs.xilinx.com/access/sources/dita/map?isLatest=true&amp;ft:locale=en-US&amp;url=ug1354-xilinx-ai-sdk">UG1354</a>).</p></li>
<li><p>The Vitis AI Library quick start guide as well as open-source can be found
<a class="reference external" href="https://gitenterprise.xilinx.com/quentonh/vitis-ai-staging/tree/master/src">here</a>.</p></li>
</ul>
</section>
<section id="vitis-ai-runtime">
<h2>Vitis AI Runtime<a class="headerlink" href="#vitis-ai-runtime" title="Permalink to this heading">¶</a></h2>
<p>The Vitis AI Runtime (VART) is a set of API functions that support integration of the DPU into software applications. VART provides a unified high-level runtime for both Data Center and Embedded targets. Key features of the Vitis AI Runtime API are:</p>
<ul class="simple">
<li><p>Asynchronous submission of jobs to the DPU</p></li>
<li><p>Asynchronous collection of jobs from the DPU</p></li>
<li><p>C++ and Python API implementations</p></li>
<li><p>Support for multi-threading and multi-process execution</p></li>
</ul>
<p>For more information on Vitis AI Runtime, refer to the following documentation:</p>
<ul class="simple">
<li><p>For the Vitis AI Runtime API reference, see <a class="reference external" href="https://docs.xilinx.com/access/sources/dita/topic?isLatest=true&amp;ft:locale=en-US&amp;url=ug1414-vitis-ai&amp;resourceid=erl1576053489624.html">VART Programming APIs</a> and <a class="reference external" href="https://docs.xilinx.com/access/sources/dita/topic?isLatest=true&amp;ft:locale=en-US&amp;url=ug1414-vitis-ai&amp;resourceid=zgy1576168058789.html">Deploying and Running the Model</a> in the Vitis AI User Guide.</p></li>
<li><p>A quick-start example to assist you in deploying VART on embedded devices is available <a class="reference external" href="https://gitenterprise.xilinx.com/quentonh/vitis-ai-staging/tree/master/src/Vitis-AI-Runtime/VART/quick_start_for_embedded.md">here</a>.</p></li>
<li><p>A number of useful tools that any developer who is leveraging VART to deploy on a custom hardware target should be aware of is available <a class="reference external" href="https://gitenterprise.xilinx.com/quentonh/vitis-ai-staging/tree/master/src/Vitis-AI-Library/usefultools">here</a>.</p></li>
<li><p>The Vitis AI Runtime is also provided as <a class="reference external" href="https://gitenterprise.xilinx.com/quentonh/vitis-ai-staging/tree/master/src">open-source</a>.</p></li>
</ul>
</section>
<section id="whole-application-acceleration">
<span id="id1"></span><h2>Whole Application Acceleration<a class="headerlink" href="#whole-application-acceleration" title="Permalink to this heading">¶</a></h2>
<p>It is typical in machine learning applications to require some degree of pre-processing as illustrated in the following example:</p>
<img alt="../_images/waa_preprocess.PNG" src="../_images/waa_preprocess.PNG" />
<p>In addition, many real-world applications for machine learning do not simply employ a single machine learning model. It is very common to cascade multiple object detection networks as a pre-cursor to a final stage (for example, classification, OCR). Throughout this pipeline the meta data must be time-stamped or otherwise attached to the buffer address of the associated frame. Pixels bounded by ROI (Region-of-Interest) predictions are cropped from the the associated frame. Each of these cropped sub-frame images are then scaled such that the X/Y dimensions of the crop match the input layer dimensions of the downstream network. Some pipelines, such as ReID, will localize, crop and scale ten or more ROIs from every frame. Each of these crops may require a different scaling factor in order to match the input dimensions of the downstream model in the pipeline. The following is an example:</p>
<img alt="../_images/waa_cascade.PNG" src="../_images/waa_cascade.PNG" />
<p>These pre-, intermediate, and post-processing operations can significantly impact the overall efficiency of the end-to-end application. This makes “Whole Application Acceleration” or WAA a very important aspect of Xilinx machine learning solutions. All developers leveraging Xilinx devices for high-performance machine learning applications should learn and understand the benefits of WAA. An excellent starting point for this can be found <a class="reference external" href="https://gitenterprise.xilinx.com/quentonh/vitis-ai-staging/tree/master/examples/waa">here</a>.</p>
<p>On a similar vein, you may wish to explore the relevance and capabilites of the <a class="reference external" href="https://xilinx.github.io/VVAS/">Xilinx Vitis Video Analytics (VVAS) SDK</a>, which while not part of Vitis AI, offers many important features for the development of end-to-end video analytics pipelines that employ multi-stage (cascaded) AI pipelines. VVAS is also applicable to designs that leverage video decoding, transcoding, RTSP streaming, and CMOS sensor interfaces. Another important differentiator of VVAS is that it directly enables software developers to leverage <a class="reference external" href="https://gstreamer.freedesktop.org/">GStreamer</a> commands to interact with the video pipeline.</p>
</section>
<section id="vitis-ai-profiler">
<h2>Vitis AI Profiler<a class="headerlink" href="#vitis-ai-profiler" title="Permalink to this heading">¶</a></h2>
<p>The Vitis AI Profiler is a set of tools that enables you to profile and visualize AI applications based on VART. Because the profiler can be enabled post deployment, there are no code changes required, making it relatively easy to use. Specifically, the Vitis AI Profiler supports profiling and visualization of machine learning pipelines deployed on
Embedded targets with the Vitis AI Runtime. In a typical machine learning pipeline, there are portions of the pipeline that are accelerated on the DPU (DPU subgraph partitions), as well as functions such as pre-processing, and/or custom operators not supported by the DPU. These additional functions may be implemented as a C/C++ kernel, or accelerated using Whole-Application Acceleration or using customized RTL. The Vitis AI Profiler enables the developer to visualize and analyze both system and graph-level performance bottlenecks. Use of the Vitis AI Profiler is a important step for developers who wish to iteratively optimize the entire inference pipeline.</p>
<p>The Vitis AI Profiler is a component of the Vitis AI toolchain installed in the VAI Docker. Source code is not provided.</p>
<ul class="simple">
<li><p>For more information on Vitis AI Profiler see the <a class="reference external" href="https://docs.xilinx.com/access/sources/dita/topic?isLatest=true&amp;ft:locale=en-US&amp;url=ug1414-vitis-ai&amp;resourceid=kdu1570699882179.html">Profiling the
Model</a>
section in the Vitis AI User Guide.</p></li>
<li><p>Examples and additional detail for the Vitis AI Profiler can be found
<a class="reference external" href="https://gitenterprise.xilinx.com/quentonh/vitis-ai-staging/tree/master/examples/Vitis-AI-Profiler">here</a>.</p></li>
<li><p>A tutorial that provides additional insights on the capabilites of
the Vitis AI Profiler is available
<a class="reference external" href="https://github.com/Xilinx/Vitis-AI-Tutorials/blob/1.4/Design_Tutorials/16-profiler_introduction/README.md">here</a>.</p></li>
</ul>
</section>
</section>


           </div>
          </div>
          
                  <style>
                        .footer {
                        position: fixed;
                        left: 0;
                        bottom: 0;
                        width: 100%;
                        }
                  </style>
				  
				  <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="workflow-model-development.html" class="btn btn-neutral float-left" title="Developing a Model" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="workflow-system-integration.html" class="btn btn-neutral float-right" title="Toolchain Integration" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021-2022, Advanced Micro Devices, Inc.
      <span class="lastupdated">Last updated on July 20, 2022.
      </span></p>
  </div>



										<div class="aem-Grid aem-Grid--16">
											<div class="aem-GridColumn aem-GridColumn--xxxlarge--none aem-GridColumn--xsmall--16 aem-GridColumn--offset--xsmall--0 aem-GridColumn--xlarge--none aem-GridColumn--xxlarge--none aem-GridColumn--default--none aem-GridColumn--offset--large--1 aem-GridColumn--xlarge--12 aem-GridColumn--offset--default--0 aem-GridColumn--xxlarge--10 aem-GridColumn--offset--xlarge--2 aem-GridColumn--offset--xxlarge--3 aem-GridColumn--offset--xxxlarge--4 aem-GridColumn--xsmall--none aem-GridColumn--large--none aem-GridColumn aem-GridColumn--large--14 aem-GridColumn--xxxlarge--8 aem-GridColumn--default--16">
												<div class="container-fluid sub-footer">

													                    <div class="row">
                        <div class="col-xs-24">
                          <p><a target="_blank" href="https://www.amd.com/en/corporate/copyright">Terms and Conditions</a> | <a target="_blank" href="https://www.amd.com/en/corporate/privacy">Privacy</a> | <a target="_blank" href="https://www.amd.com/en/corporate/cookies">Cookie Policy</a> | <a target="_blank" href="https://www.amd.com/en/corporate/trademarks">Trademarks</a> | <a target="_blank" href="https://www.amd.com/system/files/documents/statement-human-trafficking-forced-labor.pdf">Statement on Forced Labor</a> | <a target="_blank" href="https://www.amd.com/en/corporate/competition">Fair and Open Competition</a> | <a target="_blank" href="https://www.amd.com/system/files/documents/amd-uk-tax-strategy.pdf">UK Tax Strategy</a> | <a target="_blank" href="https://docs.xilinx.com/v/u/9x6YvZKuWyhJId7y7RQQKA">Inclusive Terminology</a> | <a href="https://pages.gitenterprise.xilinx.com/techdocs/Test/vvas/build/html/index.html#cookiessettings" class="ot-sdk-show-settings">Cookies Settings</a></p>
                        </div>
                    </div>
												</div>
											</div>
										</div>
										
</br>


  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>